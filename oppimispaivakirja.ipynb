{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "right-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ilmeisesti on best practice importtaa kaikki aina aluksi\n",
    "# Luento 1\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "# Luento 2\n",
    "import scrapy\n",
    "\n",
    "# Luento 3\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-consolidation",
   "metadata": {},
   "source": [
    "# Luento 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-spanish",
   "metadata": {},
   "source": [
    "### Viikon Joda-opiskelut\n",
    "\n",
    "Viikon luennon katsoin tallenteelta, mutta demoluennon ensimmäisen puoliskon katsoin livenä. Päiväkirjan laatimisessa käytetty materiaali tulee lähinnä luentomateriaaleista, mutta esimerkiksi Jupyterin käyttöönotossa hain apua YouTubesta: https://www.youtube.com/watch?v=DKiI6NfSIe8&t=2s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-wiring",
   "metadata": {},
   "source": [
    "### Datatiede?\n",
    "\n",
    "Datatiede on saanut paljon kritiikkiä siitä, että se on vain tilastotiedettä modernisoidulla nimellä ja datatieteilijä on vain tilastotieteilijä hienommalla titteliä. Asia ei todellisuudessa kuitenkaan ole näin: tilastollisen analyysin lisäksi datatieteilijän tulee hanskata monia muitakin aihealueita, kuten liiketoiminta, ohjelmointi, tietokannat sekä data tehokas viestintä yleisölleen esimerkiksi visualisoinnin kautta. Voidaan siis sanoa, että tilastotiede on osa datatiedettä.\n",
    "\n",
    "CRIPS-DM malli kuvaa mielestäni hyvin datatieteilijän työnkuvaa. Aluksi lähetään siitä, että ymmärretään omaa liiketoimintaa ja dataa. Tämän jälkeen täytyy ymmärtää, että miten ne liittyvät yhteen ja millainen data on ylipäätänsä relevanttia liiketoiminnan kannalta. Tämä data täytyy sen jälkeen ”siivota” kaikesta kyseenomaisessa tapauksessa epärelevantista datasta ja mallintaa siten, että se on helppo viestiä ja helposti ymmärrettävissä. Lopuksi datan perusteella pitää osata tehdä johtopäätöksiä liiketoiminnan tukemiseksi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-milton",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Internet ja sen mukana tulleet hullutukset kuten sosiaalinen media ovat mahdollistaneet yritysten liiketoiminnan ainoastaan datan keräämiselle ja myymiselle (Netflixissä on tosi mielenkiintoinen dokkari asiaan liittyen). Yritykset kuten Facebook, keräävät käyttäjistään mahdollisimman paljon dataa ja selvittävät sen avulla, onko kyseinen henkilö esimerkiksi kiinnostunut ostamaan uusia kenkiä. Tämän jälkeen Facebook voi myydä esimerkiksi mainospaikkoja siten, että kenkävalmistajien mainokset näkyvät vain heille, joilla todennäköisesti on intressejä ostaa kengät. Esimerkiksi Google tililtäsi näkee, mitä kaikkea Google sinusta tietää. Netflix dokkaria lainaten, ”datankerääjän todennäköisesti tietävät poliittiset näkemyksesi paremmin kuin sinä itse”.\n",
    "\n",
    "Datan käsittelyn välineiden, kuten tekoälyn kehitys on mahdollistanut myös sen, että tästä datasta voidaan helposti jalostaa tietoa. Myös laskentatehon kasvaminen ja uusien työvälineiden jatkuva keksiminen ja päivittyminen ovat olleet vauhdittamassa datatieteen kehitystä ja kasvua. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-lightweight",
   "metadata": {},
   "source": [
    "### Demo\n",
    "\n",
    "Edellä kerrotun teorian lisäksi opin myös datan käsittelemistä Jupyterilla ja Pythonilla. Alla olevan demo data on sama, kuin aiemmin linkkaamassa \"Jupyter Notebook Tutorial\"-videossa, ja se löytyy täältä: https://www.kaggle.com/ronitf/heart-disease-uci. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luetaan data ja tallennetaan muuttujaan df\n",
    "original_df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "# Kopiodaan data uuteen muuttujaan, jotta ei sörkitä vanhaa\n",
    "df = original_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tulostetaan ensimmäiset 5 riviä\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tulostetaan datatyypit\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-brisbane",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Valitaan ja summataan kolesteroliarvot iän mukaan kolesteroliarvot\n",
    "ages_chols = df.loc[:, [\"age\", \"chol\"]]\n",
    "\n",
    "age_over_50 = ages_chols[ ages_chols[\"age\"] <= 60]\n",
    "age_over_50 = age_over_50[ age_over_50[\"age\"] > 50]\n",
    "\n",
    "age_over_60 = ages_chols[ages_chols[\"age\"] <= 70]\n",
    "age_over_60 = age_over_60[age_over_60[\"age\"] >60]\n",
    "\n",
    "age_over_70 = ages_chols[ ages_chols[\"age\"] > 70 ]\n",
    "\n",
    "chol_sum_over_50 = sum(age_over_50[\"chol\"])\n",
    "chol_sum_over_60 = sum(age_over_60[\"chol\"])\n",
    "chol_sum_over_70 = sum(age_over_70[\"chol\"])\n",
    "\n",
    "# Visualisoidaan data\n",
    "df_plot = pd.DataFrame([[chol_sum_over_50, chol_sum_over_60, chol_sum_over_70]])\n",
    "df_plot.columns = ['Age over 50', 'Age over 60', 'Age over 70']\n",
    "\n",
    "df_plot.plot.bar(figsize=(13,8))\n",
    "plt.legend(loc=2)\n",
    "plt.ylabel('Cholesterol')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-temperature",
   "metadata": {},
   "source": [
    "### Viisi oivaillusta tältä viikolta\n",
    "\n",
    "1. Datatiede kattaa tilastoanalyysin lisäksi monia muita osaamisalueita\n",
    "2. Dataa kerätään jatkuvasti ja paljon\n",
    "3. Datan käsittelyn välineet kehittyvät huimaa vaihtua\n",
    "4. Opin käyttämään Jupyteria datan käsittelyn välineenä\n",
    "5. Datan mallintaminen voi mennä pienemmästäkin syntaksivirheestä pieleen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-houston",
   "metadata": {},
   "source": [
    "### Kehitysehdotukset\n",
    "\n",
    "En keksi vielä tältä viikolta kehitysehdotuksia. Haluan esittää siitä kiitokset, että vanhoilla materiaaleilla pystyy suorittamaan kurssia juuri siinä aikataulussa, mikä itselle sopii. Tämä on suuri helpostus minulle aikatauluni suunnittelun suhteen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-cycle",
   "metadata": {},
   "source": [
    "# Luento 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-break",
   "metadata": {},
   "source": [
    "### Viikon Joda-opiskelut\n",
    "Tällä viikolla katsoin sekä luennon, että demon tallenteilta. Päiväkirjan laadin luentomateriaalin avulla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-advance",
   "metadata": {},
   "source": [
    "### Datatieteen prosesista\n",
    "Datatieteen prosessiin kuuluu neljä päävaihetta: tiedon käsittely, analyysi, reflektio ja tulosten viestiminen vastaanottajalle soveltuvassa muodossa. Tästä proseduurista noin 80 % työpanoksesta menee ensimmäiseen vaiheeseen, mikä sisältää datan hankkimisen ja siivoamisen (80/20 -sääntö).  Data voidaan hakea esimerkiksi julkisten rajapintojen kautta, mittauslaitteiden avulla tai tuottamalla se manuaalisesti. Raakadatan perusteella ei usein voi suoraan tehdä analyysiä ja vetää siitä johtopäätöksiä, vaan se täytyy siivota ja formatoida uudestaan. Tämä johtuu siitä, että dataa tuskin on alun perin tuotettu sitä käyttötarkoitusta varten, mihin esimerkiksi tutkija sitä haluaa hyödyntää. Data saattaa usein sisältää myös virheitä (esim. perus kirjoitusvirheitä jne.), jotka saattavan kaataa tai aiheuttaa bugeja sitä käsittelevälle ohjelmistolle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-housing",
   "metadata": {},
   "source": [
    "### Datatieteilijä vs datainsinööri\n",
    "Yksi suurimmista eroista datatieteilijän ja datainsinöörin välillä on työprosessien eroavaisuus. ETL (Extract/Load/Transform) on tarkoitettu datainsinööreille ja DAD (Discover/Access /Distill) on datatieteilijöille. Datainsinöörin tehtävä on keskittyä datan käsittelyyn liittyviin teknisiin ratkaisuihin, kun taas datatieteilijä pyrkii luomaan datasta syvällisempää ymmärrystä ja luoda arvoa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-murray",
   "metadata": {},
   "source": [
    "### Liiketoimintarelevanssi\n",
    "Data-analytiikalla on kyky luoda yritykselle valmiudet suorituskyvyn parantamiseen. Tämä tapahtuu lisäämällä ymmärrystä liiketoimintaprosessisista. Data-analytiikan koostuu seuraavista teemoista:\n",
    "- **Kuvaileva analytiikka**, mitä on tapahtunut?\n",
    "- **Diagnosoiva analytiikka**, miksi se on tapahtunut?\n",
    "- **Ennakoiva analytiikka**, mitä todennäköisesti tulee tapahtumaan?\n",
    "- **Ohjaava analytiikka**, mitä asialle pitäisi tehdä?\n",
    "\n",
    "Vaikka data-analytiikka luo edellytykset liiketoiminnan kehittämiselle, suurin osa yrityksistä ei kuitenkaan sitä ole vielä omaksunut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-software",
   "metadata": {},
   "source": [
    "### Ryömijät ja raapijat\n",
    "Eräs tapa datankeruulle on ryömijöiden ja raapijoiden käyttö. Ryömijä on botti, joka on ohjelmoitu käymään systemaattisesti verkkosivuja läpi. Raapija on taas työkalu, joka kerää dataa verkkosivuilta. Käytännössä ryömijä ja raapija toimivat yhdessä siten, että raapija on ikään kuin ryömijän mukana ja kerää dataa samanaikaisesti, kun ryömijä käy verkkosivuja läpi. Ryömijöitä ja raapijoita käyttäessä tulee ottaa huomioon mahdolliset lailliset esteet, sillä niiden keräämä data ei välttämättä aina ole julkista. Tämä taas vaikuttaa siihen, kuinka kerättyä dataa saa käsitellä ja julkaista."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-soundtrack",
   "metadata": {},
   "source": [
    "### Demo\n",
    "Demona toteutan samanlaisen datascraperin Pythonin Scrapy-kirjastoa käyttäen. Otan tähä mallia YouTube-videosta: https://www.youtube.com/watch?v=ogPMCpcgb-E. Huomaa, että demo löytyy kokonaisuudessaan samasta repositoriosta (reddit_scraper.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asennetaan Scraoy, ja generoidaan scraperin skeleton\n",
    "!pip install scrapy\n",
    "!scrapy genspider reddit_scraper reddit.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hakee Redditin langasta r/dogs kaikki .jpg-muotoiset kuvat\n",
    "\n",
    "class RedditScraperSpider(scrapy.Spider):\n",
    "    name = 'reddit_scraper'\n",
    "    allowed_domains = ['reddit.com']\n",
    "    start_urls = ['https://www.reddit.com/r/dogs/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        links = response.xpath(\"//img/@src\")\n",
    "        html = \"\"\n",
    "\n",
    "        for link in links:\n",
    "            url = link.get()\n",
    "\n",
    "            if any(extension in url for extension in [\".jpg\"]):\n",
    "                html += \"\"\"<a href=\"{url}\" target=\"_blank\"><img src=\"{url}\" height=\"25%\" width=\"25%\"/><a/>\"\"\".format(url=url)\n",
    "\n",
    "                with open(\"dogs.html\", \"a\") as page:\n",
    "                    page.write(html)\n",
    "                    page.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajetaan scripti syöttämällä seuraava käsky komentoriville\n",
    "!scrapy runspider reddit_scraper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-tyler",
   "metadata": {},
   "source": [
    "### Viisi oivaillusta tältä viikolta\n",
    "\n",
    "1. 80/20 -sääntö: datan keräämiseen ja siivoamiseen menee usein kauemmin, kuin sen analysoimiseen\n",
    "2. Datainsinööri hoitaa datankäsittelyn teknisen toteutuksen ja datatieteilijä luo sillä arvoa\n",
    "3. Data-analytiikan neljä teemaa\n",
    "4. Ryömijän ja raapijan yhteistoiminta\n",
    "5. Ryömijän ja raapijan toteuttaminen Pythonin Scrapy-kirjastolla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-movement",
   "metadata": {},
   "source": [
    "### Kehitysehdotukset\n",
    "\n",
    "En keksi vieläkään kehitysehdotuksia. Kurssi on ollut erittäin hyvin järjestetty (tähän mennessä), ja mielestäni monet kurssinvetäjät esim. tietotekniikan puolelta voisivat ottaa tästä mallia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-haiti",
   "metadata": {},
   "source": [
    "# Luento 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-review",
   "metadata": {},
   "source": [
    "### Viikon Joda-opiskelut\n",
    "Tällä viikolla koostin oppimispäiväkirjani materiaalit vuoden 2020 Joda-totetuksen avulla. Myös YouTube-videot https://www.youtube.com/watch?v=z-EtmaFJieY sekä https://www.youtube.com/watch?v=HcqpanDadyQ toimivat viikolla oppimateriaaleina."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-liberal",
   "metadata": {},
   "source": [
    "### Koneoppiminen\n",
    "Kun ensimmäisen kerran kuulin sanat ”tekoäly” ja ”koneoppiminen”, mieleeni tulivat ensimmäisenä Terminator ja Ex Machina elokuvat, sekä ajatus siitä, että ne ovat vielä kaukana tulevaisuudessa. Asia ei kuitenkaan ole näin: me olemme käytännössä kokoa ajan tekoälyn ja koneoppimisen kanssa. Esimerkiksi Instagramissa mainokset, ehdotetut julkaisut ja ehdotetut käyttäjätilit, joita voisin olla kiinnostunut ovat kaikki asioita, josta tietokone on datan perusteella päätellyt minun olevan kiinnostunut.  Myös esimerkiksi Googlen hakukone osaa korjata kirjoitusvirheesi, koska sen on todennäköisesti tietää, mitä yritit kirjoittaa.\n",
    "\n",
    "Koneoppiminen on kaikessa yksinkertaisuudessaan tekoälyn osa-alue, joka ideana on opettaa tietokone tekemään ennusteita tai päätöksiä. Mitä enemmän dataa tietokoneelle syötetään, sitä paremmin tietokone oppii ja sitä parempia päätöksiä/ennusteita se tekee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-appliance",
   "metadata": {},
   "source": [
    "### Esimerkki\n",
    "Otetaan yksinkertainen esimerkki: opetetaan kone päättämään, onko kyseessä saksanpaimenkoira vai susi. Ihminen osaisi tehdä päätöksen pelkästään katsomalla kahta eri eläintä, mutta tietokone pyrkii ikään kuin ”purkamaan” sen saaman tiedon **piirteisiin**. Näitä piirteitä voivat tässä esimerkissä olla eläimen paino, ja pituus. Tämän jälkeen koneelle voidaan antaa harjoitteludataa:\n",
    "\n",
    "| Paino | Pituus | Eläin |\n",
    "| --- | --- | --- |\n",
    "| 42 | 121 | Susi |\n",
    "| 26 | 79 | Koira |\n",
    "| 37 | 90 | Koira |\n",
    "| ... | ... | ... |\n",
    "| 58 | 134 | Susi |\n",
    "\n",
    "Ja tämä perusteella kone oppii luomaan rajat päätöksenteolle alla olevan kuvan mukaisesti:\n",
    "\n",
    "![title](img/kuvaaja.jpeg)\n",
    "\n",
    "Kuten huomataan, osa koirista menee susirajan sisäpuolelle ja osa susista jää taas koirarajan sisälle. Harjoitusdatan perusteella tietokone ei välttämättä pysty piirtämään kovin tarkkaa rajaa koirien ja susien välille, vaan se tekee datan perusteella rajan siten, että mahdollisimman vähän susia jää koirarajan sisälle ja toisinpäin. Mitä enemmän dataa tietokone saa, sitä tarkemman rajan se osaa piirtää ja sitä päätöksiä se oppii tekemään. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-pharmaceutical",
   "metadata": {},
   "source": [
    "### Demo\n",
    "Tämä demo on käytännössä kopioitu luento/demosessiomateriaaleista. Yritän omin sanoin kuitenkin selittää, mitä missäkin tapahtuu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cosmetic-letter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\anttoni\\miniconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anttoni\\miniconda3\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\anttoni\\miniconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\anttoni\\miniconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anttoni\\miniconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\anttoni\\miniconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\anttoni\\miniconda3\\lib\\site-packages (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "# Asennetaan tarvittavat kirjastot, importit tehty muistion alussa\n",
    "!pip install sklearn\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "soviet-pencil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan ID</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Loan Status</th>\n",
       "      <th>Current Loan Amount</th>\n",
       "      <th>Term</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Years in current job</th>\n",
       "      <th>Home Ownership</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Monthly Debt</th>\n",
       "      <th>Years of Credit History</th>\n",
       "      <th>Months since last delinquent</th>\n",
       "      <th>Number of Open Accounts</th>\n",
       "      <th>Number of Credit Problems</th>\n",
       "      <th>Current Credit Balance</th>\n",
       "      <th>Maximum Open Credit</th>\n",
       "      <th>Bankruptcies</th>\n",
       "      <th>Tax Liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14dd8831-6af5-400b-83ec-68e61888a048</td>\n",
       "      <td>981165ec-3274-42f5-a3b4-d104041a9ca9</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>445412.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>709.0</td>\n",
       "      <td>1167493.0</td>\n",
       "      <td>8 years</td>\n",
       "      <td>Home Mortgage</td>\n",
       "      <td>Home Improvements</td>\n",
       "      <td>5214.74</td>\n",
       "      <td>17.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>228190.0</td>\n",
       "      <td>416746.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4771cc26-131a-45db-b5aa-537ea4ba5342</td>\n",
       "      <td>2de017a3-2e01-49cb-a581-08169e83be29</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>262328.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>Home Mortgage</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>33295.98</td>\n",
       "      <td>21.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229976.0</td>\n",
       "      <td>850784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4eed4e6a-aa2f-4c91-8651-ce984ee8fb26</td>\n",
       "      <td>5efb2b2b-bf11-4dfd-a572-3761a2694725</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2231892.0</td>\n",
       "      <td>8 years</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>29200.53</td>\n",
       "      <td>14.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>297996.0</td>\n",
       "      <td>750090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a</td>\n",
       "      <td>e777faab-98ae-45af-9a86-7ce5b33b1011</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>347666.0</td>\n",
       "      <td>Long Term</td>\n",
       "      <td>721.0</td>\n",
       "      <td>806949.0</td>\n",
       "      <td>3 years</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>8741.90</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256329.0</td>\n",
       "      <td>386958.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d4062e70-befa-4995-8643-a0de73938182</td>\n",
       "      <td>81536ad9-5ccf-4eb8-befb-47a4d608658e</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>176220.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 years</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>20639.70</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253460.0</td>\n",
       "      <td>427174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Loan ID                           Customer ID  \\\n",
       "0  14dd8831-6af5-400b-83ec-68e61888a048  981165ec-3274-42f5-a3b4-d104041a9ca9   \n",
       "1  4771cc26-131a-45db-b5aa-537ea4ba5342  2de017a3-2e01-49cb-a581-08169e83be29   \n",
       "2  4eed4e6a-aa2f-4c91-8651-ce984ee8fb26  5efb2b2b-bf11-4dfd-a572-3761a2694725   \n",
       "3  77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a  e777faab-98ae-45af-9a86-7ce5b33b1011   \n",
       "4  d4062e70-befa-4995-8643-a0de73938182  81536ad9-5ccf-4eb8-befb-47a4d608658e   \n",
       "\n",
       "  Loan Status  Current Loan Amount        Term  Credit Score  Annual Income  \\\n",
       "0  Fully Paid             445412.0  Short Term         709.0      1167493.0   \n",
       "1  Fully Paid             262328.0  Short Term           NaN            NaN   \n",
       "2  Fully Paid           99999999.0  Short Term         741.0      2231892.0   \n",
       "3  Fully Paid             347666.0   Long Term         721.0       806949.0   \n",
       "4  Fully Paid             176220.0  Short Term           NaN            NaN   \n",
       "\n",
       "  Years in current job Home Ownership             Purpose  Monthly Debt  \\\n",
       "0              8 years  Home Mortgage   Home Improvements       5214.74   \n",
       "1            10+ years  Home Mortgage  Debt Consolidation      33295.98   \n",
       "2              8 years       Own Home  Debt Consolidation      29200.53   \n",
       "3              3 years       Own Home  Debt Consolidation       8741.90   \n",
       "4              5 years           Rent  Debt Consolidation      20639.70   \n",
       "\n",
       "   Years of Credit History  Months since last delinquent  \\\n",
       "0                     17.2                           NaN   \n",
       "1                     21.1                           8.0   \n",
       "2                     14.9                          29.0   \n",
       "3                     12.0                           NaN   \n",
       "4                      6.1                           NaN   \n",
       "\n",
       "   Number of Open Accounts  Number of Credit Problems  Current Credit Balance  \\\n",
       "0                      6.0                        1.0                228190.0   \n",
       "1                     35.0                        0.0                229976.0   \n",
       "2                     18.0                        1.0                297996.0   \n",
       "3                      9.0                        0.0                256329.0   \n",
       "4                     15.0                        0.0                253460.0   \n",
       "\n",
       "   Maximum Open Credit  Bankruptcies  Tax Liens  \n",
       "0             416746.0           1.0        0.0  \n",
       "1             850784.0           0.0        0.0  \n",
       "2             750090.0           0.0        0.0  \n",
       "3             386958.0           0.0        0.0  \n",
       "4             427174.0           0.0        0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ladataan data\n",
    "original_df = pd.read_csv(\"credit_train.csv\")\n",
    "df = original_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "experienced-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data täytyy ensi siivota, ennen kuin sitä voi käsitellä.\n",
    "Tämä funktio siivoaa datan (esim. poistaa NaN-rivit) ja muokaa datan\n",
    "meidän käyttötarkoitukseen sopivaan muotoon\n",
    "\"\"\"\n",
    "\n",
    "def siivoaData(data, slice=1.0):\n",
    "\n",
    "    poistettavatMuuttujat = ['Loan ID','Customer ID']\n",
    "    data = data.drop(poistettavatMuuttujat, axis=1)\n",
    "\n",
    "    sarakkeet =['Current Loan Amount','Credit Score','Annual Income','Years of Credit History',\n",
    "            'Months since last delinquent','Number of Open Accounts','Number of Credit Problems',\n",
    "           'Current Credit Balance','Maximum Open Credit','Bankruptcies','Tax Liens']\n",
    "    muuttujanTäyttäjä = Imputer()\n",
    "    data[sarakkeet] = muuttujanTäyttäjä.fit_transform(data[sarakkeet])\n",
    "    data[sarakkeet] = data[sarakkeet].astype(int)\n",
    "\n",
    "    data=data.dropna()\n",
    "\n",
    "    if slice > 0 and slice < 1:\n",
    "        mid_point = int(len(data)*slice)\n",
    "        data = data.loc[:mid_point]\n",
    "\n",
    "    y = data['Loan Status']\n",
    "    new_y = []\n",
    "    for i in y:\n",
    "        if i == 'Fully Paid':\n",
    "            new_y.append(1)\n",
    "        else:\n",
    "            new_y.append(0)\n",
    "    data = data.drop('Loan Status', axis=1)\n",
    "\n",
    "    data = pd.get_dummies(data)\n",
    "    dataMean = np.mean(data, axis=0)\n",
    "    dataDev = np.std(data, axis=0)\n",
    "    norm_x = (data - dataMean) / dataDev\n",
    "\n",
    "    x = data.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    normMinMax = pd.DataFrame(x_scaled)\n",
    "\n",
    "    return norm_x, normMinMax, data, new_y, dataMean, dataDev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "affected-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tämä funtio jaksaa datan opetus- ja testidataksi\n",
    "def opetusTestiJako(xMinMax, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.25, random_state=33)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "intensive-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harjoitteludatan tarkuus-arvo\n",
      "0.8219342085114084\n",
      "Restidatan tarkuus-arvo\n",
      "0.8218834829818333\n",
      "Luokitteluraportti\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.20      0.34      5337\n",
      "           1       0.81      1.00      0.90     18608\n",
      "\n",
      "    accuracy                           0.82     23945\n",
      "   macro avg       0.90      0.60      0.62     23945\n",
      "weighted avg       0.85      0.82      0.77     23945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Siivotan data\n",
    "x, xMinMax, xNoNorm, y, xMean, xDev = siivoaData(df)\n",
    "\n",
    "# Jaetaan se opetus- ja testidataksi\n",
    "_train, x_test, y_train, y_test = opetusTestiJako(x,y)\n",
    "xMinMax_train, xMinMax_test, y_train, y_test = opetusTestiJako(xMinMax,y)\n",
    "xNoNorm_train, xNoNorm_test, y_train, y_test = opetusTestiJako(xNoNorm,y)\n",
    "\n",
    "# Luodaan datan avulla malli\n",
    "clf = SGDClassifier()\n",
    "clf.fit(xNoNorm_train, y_train)\n",
    "\n",
    "# Lasketaan harjoitteludatan tarkuus-arvo\n",
    "y_train_pred = clf.predict(xNoNorm_train)\n",
    "print(\"Harjoitteludatan tarkuus-arvo\")\n",
    "print (metrics.accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# Lasketaan testidatan tarkuus-arvo\n",
    "y_pred = clf.predict(xNoNorm_test)\n",
    "print(\"Restidatan tarkuus-arvo\")\n",
    "print (metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Näytettään luokitteluraportti\n",
    "print(\"Luokitteluraportti\")\n",
    "print (metrics.classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
